{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f5ae98",
   "metadata": {},
   "source": [
    "# このノートブックでは\n",
    "\n",
    "transformerをスクリプト化し、学習の様子がよくわかるようにコーディングする。\n",
    "\n",
    "なお、モデルの隠蔽だけを行い。トレーニングのコードはノートブックで書くつもり。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da34c5c7",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96ff4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_fontja\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "from tokenizers import SentencePieceUnigramTokenizer\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79eab222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(f\"{os.path.dirname(os.getcwd())}/modules\")\n",
    "from transformer_scratch.transformer import Transformer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f70acd",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b325647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'footnote', 'meta'],\n",
       "    num_rows: 16951\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"globis-university/aozorabunko-clean\", split=\"train\")\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fede3d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16951"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = ds[\"text\"]\n",
    "len(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ffb0a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "847.55"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffa2d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データセットを直接渡すとメモリを圧迫するため、ジェネレータをかませる\n",
    "# def ds_iter():\n",
    "#     for item in ds[\"text\"]:\n",
    "#         yield item\n",
    "\n",
    "\n",
    "# spm.SentencePieceTrainer.Train(\n",
    "#     sentence_iterator=ds_iter(),\n",
    "#     model_prefix=\"trained/tokenizer/sp_jawiki\",\n",
    "#     vocab_size=8000,\n",
    "#     model_type=\"unigram\",\n",
    "#     character_coverage=0.9995,  # どの程度の文字をカバーするか。これより使用頻度の低い文字はUNKになる\n",
    "#     train_extremely_large_corpus=True,\n",
    "#     unk_id=0,\n",
    "#     bos_id=1,\n",
    "#     eos_id=2,\n",
    "#     pad_id=3,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa7fe59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "297.04s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-14 06:24:28--  https://raw.githubusercontent.com/google/sentencepiece/master/python/src/sentencepiece/sentencepiece_model_pb2.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6257 (6.1K) [text/plain]\n",
      "Saving to: ‘sentencepiece_model_pb2.py’\n",
      "\n",
      "sentencepiece_model 100%[===================>]   6.11K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-12-14 06:24:28 (82.2 MB/s) - ‘sentencepiece_model_pb2.py’ saved [6257/6257]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "303.02s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "# !pip install protobuf\n",
    "!wget https://raw.githubusercontent.com/google/sentencepiece/master/python/src/sentencepiece/sentencepiece_model_pb2.py\n",
    "tokenizer = SentencePieceUnigramTokenizer.from_spm(\n",
    "    \"../trained/tokenizer/sp_jawiki.model\"\n",
    ")\n",
    "\n",
    "!rm sentencepiece_model_pb2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66616d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(vocabulary_size=8000, model=SentencePieceUnigram)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f93bc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10639"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204cd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "909c2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "# これをすると、なぜかメタスペースが入ってしまう。\n",
    "# tokenizer.post_processor = TemplateProcessing(\n",
    "#     single=\"<s> $A </s>\", # BOS, EOSで囲む処理を指定\n",
    "#     special_tokens=[\n",
    "#         (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "#         (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "#     ],\n",
    "# )\n",
    "# tokenizer.save(\"trained/tokenizer/jawiki.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14890f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"../trained/tokenizer/jawiki.json\"\n",
    ")\n",
    "tokenizer.add_special_tokens(\n",
    "    {\n",
    "        \"unk_token\": \"<unk>\",\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"pad_token\": \"<pad>\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce1d600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenizer(ds_train[:100])\n",
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "914ec293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56d7e37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430990"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sum(tokenized[\"input_ids\"], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054d72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73268300"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_token = 430990 * 170\n",
    "print(f\"{all_token=:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f465d1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 45, 1126, 384, 576, 8, 894, 384, 576, 9, 3477, 820, 15, 441]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"人工知能は人間の知能を超えるか？\"\n",
    "ids = tokenizer.encode(text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcdc4dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'か?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([7, 45, 1126])\n",
    "tokenizer.decode([15, 441])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa154e38",
   "metadata": {},
   "source": [
    "tokenizerができた。\n",
    "\n",
    "tokenizerはpaddingまで自動でやってくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "361b00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import DataCollatorForLanguageModeling\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d0e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collatorを作る。\n",
    "# dataloaderに渡されたデータはlist型でcollate_fnに渡され、collateの処理が走る。\n",
    "# ここではtokenizerに渡すという処理を噛ませる。\n",
    "def data_collator(batch: list):\n",
    "    return tokenizer(\n",
    "        batch,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=1024,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a06508d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   7,   57, 1322,  ...,   30,  117,   24],\n",
       "        [   7,    8,   16,  ...,  235,    4,   94],\n",
       "        [   7,  123,  353,  ...,    4,  433,  197],\n",
       "        ...,\n",
       "        [ 534,   42,  559,  ...,   13,    4,  133],\n",
       "        [ 534,    7,  638,  ...,  397,  502, 2613],\n",
       "        [   7,  517, 1059,  ...,  131, 2809,    9]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    ds[\"text\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f00f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "797dbec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   7,  408, 3782,  ...,    5, 1437, 1287],\n",
       "        [   7,  319,    5,  ...,    3,    3,    3],\n",
       "        [   7, 4203,   51,  ...,   29,  326,    6],\n",
       "        ...,\n",
       "        [2596, 3759,   18,  ...,    3,    3,    3],\n",
       "        [   7,  559, 1565,  ..., 4772, 1281, 2889],\n",
       "        [   7, 6823,  234,  ...,   53,    6,   42]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239cb9b",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a56aec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "n_head = 8\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "n_layers = 6\n",
    "context_window = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83280df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_param=27,638,592\n",
      "model_size=110,554,368\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(\n",
    "    vocab_size, n_head, d_model, d_ff, n_layers, context_window\n",
    ")\n",
    "\n",
    "# transformer\n",
    "n_param = sum(p.numel() for p in transformer.parameters() if p.requires_grad)\n",
    "print(f\"{n_param=:,}\")\n",
    "# 1億2000万のパラメータ数！！！\n",
    "# float32の場合，1パラメータ4バイト換算される．\n",
    "model_size = n_param * 4\n",
    "print(f\"{model_size=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f654ac3",
   "metadata": {},
   "source": [
    "0.03Bモデルみたいな感じのができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3897801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): Embedding(8000, 512)\n",
       "  (transformer_layers): Sequential(\n",
       "    (0): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=8000, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f04ce3",
   "metadata": {},
   "source": [
    "- input: tokenizeされたデータ\n",
    "- output: sortmaxの確率分布\n",
    "- loss: cross entropy loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a835f010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   7,  408, 3782,  ...,    5, 1437, 1287],\n",
       "        [   7,  319,    5,  ...,    3,    3,    3],\n",
       "        [   7, 4203,   51,  ...,   29,  326,    6],\n",
       "        ...,\n",
       "        [2596, 3759,   18,  ...,    3,    3,    3],\n",
       "        [   7,  559, 1565,  ..., 4772, 1281, 2889],\n",
       "        [   7, 6823,  234,  ...,   53,    6,   42]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x = sample[\"input_ids\"]\n",
    "sample_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98fc517d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   7,  408, 3782,  ...,    5, 1437, 1287])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce924cb",
   "metadata": {},
   "source": [
    "$$\n",
    "loss = -\\sum \\log p(x_{t}|x_{<t})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c38bf",
   "metadata": {},
   "source": [
    "transformer: n個のsequenceを入れると、n個のsequenceを出す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92ac7212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"input_ids\"][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de1e13d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   7,  408, 3782,  ...,    5, 1437, 1287])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d89e70",
   "metadata": {},
   "source": [
    "$$\n",
    "x = x_1, x_2, ..., x_T\n",
    "\\\\\n",
    "y = \\text{transformer}(x) = y_1, y_2, ..., y_T こいつらは確率分布\n",
    "\\\\\n",
    "y_t = \\text{transformer}(x_{<{t}})\n",
    "\\\\\n",
    "y_t = p(x_{{t}}|x_{<{t}})\n",
    "\n",
    "\n",
    "x = x_1, x_2, ..., x_T\n",
    "\n",
    "input:x_1\n",
    "label:x_2\n",
    "\n",
    "input:x_1, x_2\n",
    "label:x_3\n",
    "\n",
    "input:x_1, x_2,...x_t\n",
    "label:x_{t+1}\n",
    "\n",
    "input:x_1, x_2,...x_{T-1}\n",
    "label:x_{T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b07bc95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   7,  408, 3782,  ...,    5, 1437, 1287])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f73a02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = sample[\"input_ids\"][0].clone()\n",
    "sample_input = sample_input[:-1]\n",
    "\n",
    "sample_super = sample[\"input_ids\"][0].clone()\n",
    "sample_super = sample_super[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ddb95ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7, 408])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e21143f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2465)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_super[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27308837",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = sample_input.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7866e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   7,  408, 3782,  ...,  318,    5, 1437]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb56ed",
   "metadata": {},
   "source": [
    "以下が予測と教師のペア"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aba18adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1023, 8000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(sample_input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d856b671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1023])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_super.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f661b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c63eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習率スケジューラー\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d226db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "# 8. OneCycleLR\n",
    "scheduler = lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.1,\n",
    "    total_steps=10000,\n",
    "    pct_start=0.3,\n",
    "    anneal_strategy=\"cos\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93c3a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    ds[\"text\"], shuffle=True, batch_size=32, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79760b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vital-sunset-2</strong> at: <a href='https://wandb.ai/s2122068-/transformer/runs/qbkpd30i' target=\"_blank\">https://wandb.ai/s2122068-/transformer/runs/qbkpd30i</a><br> View project at: <a href='https://wandb.ai/s2122068-/transformer' target=\"_blank\">https://wandb.ai/s2122068-/transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251213_182730-qbkpd30i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/dl_scratch/notebooks/wandb/run-20251213_183845-zrt45e2g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s2122068-/transformer/runs/zrt45e2g' target=\"_blank\">winter-moon-3</a></strong> to <a href='https://wandb.ai/s2122068-/transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s2122068-/transformer' target=\"_blank\">https://wandb.ai/s2122068-/transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s2122068-/transformer/runs/zrt45e2g' target=\"_blank\">https://wandb.ai/s2122068-/transformer/runs/zrt45e2g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    # entity=\"my-awesome-team-name\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"transformer\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config=config,\n",
    "    reinit=True,\n",
    ")\n",
    "\n",
    "# config = wandb.config\n",
    "\n",
    "# # Simulate training.\n",
    "# epochs = 10\n",
    "# offset = random.random() / 5\n",
    "# for epoch in range(2, epochs):\n",
    "#     acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
    "#     loss = 2**-epoch + random.random() / epoch + offset\n",
    "\n",
    "#     # Log metrics to wandb.\n",
    "#     run.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# # Finish the run and upload any remaining data.\n",
    "# run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9add111",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97e21492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3093829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "# import math\n",
    "\n",
    "# # Deductive Prerequisites\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "# wandb.watch(model, log=\"all\", log_freq=500)\n",
    "# scaler = GradScaler()\n",
    "# max_grad_norm = 1.0\n",
    "# model.train()\n",
    "\n",
    "# global_step = 0  # Counter for x-axis continuity\n",
    "\n",
    "# # 2. Training Loop\n",
    "# # ---------------------------------------------------------\n",
    "# for epoch in range(config[\"epochs\"]):\n",
    "#     running_loss = 0.0\n",
    "#     progress_bar = tqdm(\n",
    "#         enumerate(train_dataloader), total=len(train_dataloader)\n",
    "#     )\n",
    "\n",
    "#     # --- Inner Loop (Batch Optimization) ---\n",
    "#     for i, data in progress_bar:\n",
    "#         input_ids = data[\"input_ids\"].to(device)\n",
    "\n",
    "#         # Causal Shift Logic\n",
    "#         inputs = input_ids[:, :-1]\n",
    "#         targets = input_ids[:, 1:]\n",
    "\n",
    "#         optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "#         with autocast(enabled=(device.type == \"cuda\")):\n",
    "#             outputs = model(inputs)\n",
    "#             logits = outputs.logits if hasattr(outputs, \"logits\") else outputs\n",
    "#             loss = criterion(\n",
    "#                 logits.reshape(-1, logits.size(-1)), targets.reshape(-1)\n",
    "#             )\n",
    "\n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.unscale_(optimizer)\n",
    "#         # Capture Total Norm before update to diagnose exploding gradients\n",
    "#         # total_norm = sqrt(sum(||grad_i||^2))\n",
    "#         total_norm = torch.nn.utils.clip_grad_norm_(\n",
    "#             model.parameters(), config[\"max_grad_norm\"]\n",
    "#         )\n",
    "\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "\n",
    "#         # Stats Accumulation\n",
    "#         running_loss += loss.item()\n",
    "#         # Logging Frequency (Inductive Sampling)\n",
    "#         # Logging every step is noisy; every 100 steps creates a smoother trend.\n",
    "#         if i % 100 == 99:\n",
    "#             avg_loss = running_loss / 100\n",
    "#             # Mathematical transformation: PPL = exp(CrossEntropy)\n",
    "#             try:\n",
    "#                 perplexity = math.exp(avg_loss)\n",
    "#             except OverflowError:\n",
    "#                 perplexity = float(\"inf\")\n",
    "\n",
    "#             current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "#             # --- WandB Logging Point ---\n",
    "#             wandb.log(\n",
    "#                 {\n",
    "#                     \"train/loss\": avg_loss,\n",
    "#                     \"train/perplexity\": perplexity,\n",
    "#                     \"train/learning_rate\": current_lr,\n",
    "#                     \"train/grad_norm\": total_norm,  # Critical for tracking stability\n",
    "#                     \"epoch\": epoch,\n",
    "#                 },\n",
    "#                 step=global_step,\n",
    "#             )\n",
    "#             progress_bar.set_description(\n",
    "#                 f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Norm: {total_norm:.2f}\"\n",
    "#             )\n",
    "#             running_loss = 0.0\n",
    "#         global_step += 1\n",
    "\n",
    "#     # --- Outer Loop (Epoch Management) ---\n",
    "#     scheduler.step()\n",
    "\n",
    "#     current_lr = scheduler.get_last_lr()[0]\n",
    "#     print(f\"Epoch {epoch+1} Completed. LR updated to: {current_lr:.2e}\")\n",
    "\n",
    "# # Finalize\n",
    "# wandb.finish()\n",
    "# print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d834d077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/dl_scratch/notebooks/wandb/run-20251213_184821-1ayj6kg8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8' target=\"_blank\">cool-firefly-5</a></strong> to <a href='https://wandb.ai/s2122068-/transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s2122068-/transformer' target=\"_blank\">https://wandb.ai/s2122068-/transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8' target=\"_blank\">https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 7.1452: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest', 'best'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 7.1382: 100%|██████████| 530/530 [03:42<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest', 'best'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 7.1292: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest', 'best'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 7.1280: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest', 'best'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 7.1257: 100%|██████████| 530/530 [03:42<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest', 'best'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 7.1185: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest', 'best'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 7.1291: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 7.1218: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 7.1285: 100%|██████████| 530/530 [03:42<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 7.1319: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoint_latest.pth (Aliases: ['latest'])\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/loss</td><td>█▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▁▁▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train/loss</td><td>7.13194</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cool-firefly-5</strong> at: <a href='https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8' target=\"_blank\">https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8</a><br> View project at: <a href='https://wandb.ai/s2122068-/transformer' target=\"_blank\">https://wandb.ai/s2122068-/transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251213_184821-1ayj6kg8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# 1. Configuration & Initialization\n",
    "# ---------------------------------------------------------\n",
    "config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"transformer\",\n",
    "    \"dataset\": \"globis-university/aozorabunko-clean\",\n",
    "    \"scheduler_type\": \"StepLR\",\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"batch_size\": 32,\n",
    "    \"n_head\": 8,\n",
    "    \"d_model\": 512,\n",
    "    \"d_ff\": 2048,\n",
    "    \"n_layers\": 6,\n",
    "    \"context_window\": 1024,\n",
    "    \"epochs\": 10,\n",
    "    \"save_dir\": \"./checkpoints\",  # Local storage path\n",
    "}\n",
    "\n",
    "# Create local directory strictly\n",
    "os.makedirs(config[\"save_dir\"], exist_ok=True)\n",
    "\n",
    "run = wandb.init(project=\"transformer\", config=config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "n_head = 8\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "n_layers = 6\n",
    "context_window = 1024\n",
    "model = Transformer(\n",
    "    vocab_size, n_head, d_model, d_ff, n_layers, context_window\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# outputs = batch, seq_len, vocab\n",
    "# label = batch, seq_len, vocab\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "scaler = GradScaler()\n",
    "\n",
    "model.train()\n",
    "\n",
    "global_step = 0\n",
    "best_loss = float(\"inf\")  # For comparison\n",
    "\n",
    "\n",
    "# 2. Helper Function: Checkpoint Saver\n",
    "# ---------------------------------------------------------\n",
    "def save_checkpoint(state, filename, is_best=False):\n",
    "    \"\"\"\n",
    "    Saves the state dict locally and logs it as a W&B artifact.\n",
    "    \"\"\"\n",
    "    save_path = os.path.join(config[\"save_dir\"], filename)\n",
    "    torch.save(state, save_path)\n",
    "\n",
    "    # Create Artifact logic\n",
    "    # type=\"model\" allows W&B to visualize model lineage\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f\"transformer-model-{wandb.run.id}\",\n",
    "        type=\"model\",\n",
    "        metadata=state[\"config\"],  # Attach config for traceability\n",
    "    )\n",
    "    artifact.add_file(save_path)\n",
    "\n",
    "    # Assign aliases for easy retrieval (e.g., 'best', 'latest')\n",
    "    aliases = [\"latest\"]\n",
    "    if is_best:\n",
    "        aliases.append(\"best\")\n",
    "    wandb.log_artifact(artifact, aliases=aliases)\n",
    "    print(f\"Saved checkpoint: {filename} (Aliases: {aliases})\")\n",
    "\n",
    "\n",
    "# 3. Training Loop\n",
    "# ---------------------------------------------------------\n",
    "try:\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(\n",
    "            enumerate(train_dataloader), total=len(train_dataloader)\n",
    "        )\n",
    "        # --- Inner Loop ---\n",
    "        for i, data in progress_bar:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            inputs, targets = input_ids[:, :-1], input_ids[:, 1:]\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast(enabled=(device.type == \"cuda\")):\n",
    "                outputs = model(inputs)\n",
    "                logits = (\n",
    "                    outputs.logits if hasattr(outputs, \"logits\") else outputs\n",
    "                )\n",
    "                loss = criterion(\n",
    "                    logits.reshape(-1, logits.size(-1)), targets.reshape(-1)\n",
    "                )\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), config[\"max_grad_norm\"]\n",
    "            )\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                avg_loss = running_loss / 100\n",
    "                wandb.log(\n",
    "                    {\"train/loss\": avg_loss, \"epoch\": epoch}, step=global_step\n",
    "                )\n",
    "                progress_bar.set_description(\n",
    "                    f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\"\n",
    "                )\n",
    "                running_loss = 0.0\n",
    "            global_step += 1\n",
    "\n",
    "        # --- End of Epoch Management ---\n",
    "        scheduler.step()\n",
    "        # Calculate Validation Metric (Here simplified as last train loss for demo)\n",
    "        # In reality, insert Validation Loop here.\n",
    "        epoch_loss = avg_loss\n",
    "        is_best = epoch_loss < best_loss\n",
    "        if is_best:\n",
    "            best_loss = epoch_loss\n",
    "\n",
    "        # --- Construct Checkpoint State ---\n",
    "        # deductive reasoning: To resume, we need ALL changing variables.\n",
    "        checkpoint_state = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"scaler_state_dict\": scaler.state_dict(),\n",
    "            \"loss\": epoch_loss,\n",
    "            \"config\": config,\n",
    "        }\n",
    "\n",
    "        # Save 'latest' every epoch (Overwrites to save space locally, versions in W&B)\n",
    "        save_checkpoint(\n",
    "            checkpoint_state, \"checkpoint_latest.pth\", is_best=is_best\n",
    "        )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted by user. Saving emergency checkpoint...\")\n",
    "    # Emergency Save Logic\n",
    "    checkpoint_state = {\n",
    "        \"epoch\": epoch,  # current epoch\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"config\": config,\n",
    "    }\n",
    "    save_checkpoint(checkpoint_state, \"checkpoint_interrupted.pth\")\n",
    "\n",
    "finally:\n",
    "    wandb.finish()\n",
    "    print(\"Training process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06610852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/dl_scratch/notebooks/wandb/run-20251213_193402-1ayj6kg8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8' target=\"_blank\">cool-firefly-5</a></strong> to <a href='https://wandb.ai/s2122068-/transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s2122068-/transformer' target=\"_blank\">https://wandb.ai/s2122068-/transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8' target=\"_blank\">https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ./checkpoints/checkpoint_latest.pth...\n",
      "Resumed successfully. Starting from Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Loss: 7.1294: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Loss: 7.1268: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Loss: 7.1267: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Loss: 7.1290: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Loss: 7.1275: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Loss: 7.1249: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Loss: 7.1261: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Loss: 7.1264: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Loss: 7.1205: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 7.1274: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Loss: 7.1201: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Loss: 7.1245: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Loss: 7.1350: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Loss: 7.1328: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Loss: 7.1251: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Loss: 7.1270: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Loss: 7.1288: 100%|██████████| 530/530 [03:44<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Loss: 7.1216: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Loss: 7.1251: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Loss: 7.1270: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Loss: 7.1291: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Loss: 7.1275: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Loss: 7.1261: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Loss: 7.1215: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Loss: 7.1294: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Loss: 7.1283: 100%|██████████| 530/530 [03:45<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Loss: 7.1211: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Loss: 7.1266: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Loss: 7.1160: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Loss: 7.1167: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Loss: 7.1303: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Loss: 7.1221: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Loss: 7.1229: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Loss: 7.1252: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Loss: 7.1285: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Loss: 7.1233: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Loss: 7.1300: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Loss: 7.1258: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Loss: 7.1267: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Loss: 7.1214: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Loss: 7.1222: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Loss: 7.1220: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Loss: 7.1239: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Loss: 7.1248: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Loss: 7.1269: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Loss: 7.1225: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Loss: 7.1215: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Loss: 7.1287: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Loss: 7.1157: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Loss: 7.1227: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Loss: 7.1285: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Loss: 7.1264: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Loss: 7.1254: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Loss: 7.1281: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65 | Loss: 7.1281: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Loss: 7.1217: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Loss: 7.1205: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Loss: 7.1129: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Loss: 7.1219: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70 | Loss: 7.1288: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Loss: 7.1197: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Loss: 7.1242: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Loss: 7.1213: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Loss: 7.1177: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Loss: 7.1309: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Loss: 7.1204: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Loss: 7.1226: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Loss: 7.1204: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Loss: 7.1263: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80 | Loss: 7.1222: 100%|██████████| 530/530 [03:44<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81 | Loss: 7.1143: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82 | Loss: 7.1232: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83 | Loss: 7.1232: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84 | Loss: 7.1230: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85 | Loss: 7.1146: 100%|██████████| 530/530 [03:46<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86 | Loss: 7.1183: 100%|██████████| 530/530 [03:45<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87 | Loss: 7.1233: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88 | Loss: 7.1186: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89 | Loss: 7.1249: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90 | Loss: 7.1241: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91 | Loss: 7.1225: 100%|██████████| 530/530 [03:42<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92 | Loss: 7.1210: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93 | Loss: 7.1319: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94 | Loss: 7.1308: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95 | Loss: 7.1301: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96 | Loss: 7.1269: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97 | Loss: 7.1192: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98 | Loss: 7.1214: 100%|██████████| 530/530 [03:44<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Loss: 7.1246: 100%|██████████| 530/530 [03:43<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Loss: 7.1231: 100%|██████████| 530/530 [03:45<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 saved.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>train/loss</td><td>▅▄▅▂▅▄▆▆▆▅▆▄▄▄▄▄█▄▅▄▂▄▆▆▆▆▆▃▄▄▄▃▄▅▆▂▄▁▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>train/loss</td><td>7.12314</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cool-firefly-5</strong> at: <a href='https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8' target=\"_blank\">https://wandb.ai/s2122068-/transformer/runs/1ayj6kg8</a><br> View project at: <a href='https://wandb.ai/s2122068-/transformer' target=\"_blank\">https://wandb.ai/s2122068-/transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251213_193402-1ayj6kg8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# 1. Configuration\n",
    "# ---------------------------------------------------------\n",
    "config = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"transformer\",\n",
    "    \"dataset\": \"globis-university/aozorabunko-clean\",\n",
    "    \"scheduler_type\": \"StepLR\",\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"batch_size\": 32,\n",
    "    \"n_head\": 8,\n",
    "    \"d_model\": 512,\n",
    "    \"d_ff\": 2048,\n",
    "    \"n_layers\": 6,\n",
    "    \"context_window\": 1024,\n",
    "    \"epochs\": 100,\n",
    "    \"save_dir\": \"./checkpoints\",  # Local storage path\n",
    "    \"resume_checkpoint\": \"./checkpoints/checkpoint_latest.pth\",\n",
    "}\n",
    "prev_run_id = \"1ayj6kg8\"\n",
    "\n",
    "os.makedirs(config[\"save_dir\"], exist_ok=True)\n",
    "\n",
    "# WandB: resume=\"allow\" でIDを指定すればグラフを継続できますが、\n",
    "\n",
    "# 以前のRun IDを取得できた場合\n",
    "wandb.init(id=prev_run_id, project=\"transformer\", resume=\"allow\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# モデル・Optimizer・Scheduler・Scalerの初期化（構造は定義しておく必要がある）\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 2. Resuming Logic (Inductive State Restoration)\n",
    "# ---------------------------------------------------------\n",
    "start_epoch = 0  # Default\n",
    "\n",
    "if config[\"resume_checkpoint\"] and os.path.exists(config[\"resume_checkpoint\"]):\n",
    "    print(f\"Loading checkpoint from {config['resume_checkpoint']}...\")\n",
    "\n",
    "    # map_location is crucial to prevent device mismatch errors\n",
    "    checkpoint = torch.load(config[\"resume_checkpoint\"], map_location=device)\n",
    "\n",
    "    # Restore States\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "\n",
    "    # Calculate next start epoch\n",
    "    # If saved at end of epoch 10, checkpoint['epoch'] is usually 10 (or 11 depending on save logic).\n",
    "    # Assuming previous code saved 'epoch': epoch + 1\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "    print(f\"Resumed successfully. Starting from Epoch {start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"No checkpoint found or specified. Starting fresh training.\")\n",
    "\n",
    "# 3. Training Loop with Dynamic Range\n",
    "# ---------------------------------------------------------\n",
    "# Deductive logic: Loop must run from start_epoch to total target epochs\n",
    "if start_epoch >= config[\"epochs\"]:\n",
    "    print(\n",
    "        f\"Training already reached target epochs ({config['epochs']}). Exiting.\"\n",
    "    )\n",
    "    exit()\n",
    "\n",
    "global_step = start_epoch * len(\n",
    "    train_dataloader\n",
    ")  # Update step counter for WandB consistency\n",
    "\n",
    "for epoch in range(start_epoch, config[\"epochs\"]):\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(train_dataloader), total=len(train_dataloader)\n",
    "    )\n",
    "\n",
    "    model.train()  # Ensure mode is train\n",
    "\n",
    "    # --- Inner Loop ---\n",
    "    for i, data in progress_bar:\n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        inputs, targets = input_ids[:, :-1], input_ids[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(enabled=(device.type == \"cuda\")):\n",
    "            outputs = model(inputs)\n",
    "            logits = outputs.logits if hasattr(outputs, \"logits\") else outputs\n",
    "            loss = criterion(\n",
    "                logits.reshape(-1, logits.size(-1)), targets.reshape(-1)\n",
    "            )\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), config[\"max_grad_norm\"]\n",
    "        )\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            avg_loss = running_loss / 100\n",
    "            wandb.log(\n",
    "                {\"train/loss\": avg_loss, \"epoch\": epoch}, step=global_step\n",
    "            )\n",
    "            progress_bar.set_description(\n",
    "                f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\"\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    # --- Outer Loop ---\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save Logic (Same as before)\n",
    "    checkpoint_state = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict(),\n",
    "        \"config\": config,\n",
    "    }\n",
    "    save_path = os.path.join(config[\"save_dir\"], \"checkpoint_latest.pth\")\n",
    "    torch.save(checkpoint_state, save_path)\n",
    "\n",
    "    # WandB artifact logic here...\n",
    "    print(f\"Epoch {epoch+1} saved.\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92d083",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8facc70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37aa1a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "n_head = 8\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "n_layers = 6\n",
    "context_window = 1024\n",
    "model = Transformer(\n",
    "    vocab_size, n_head, d_model, d_ff, n_layers, context_window\n",
    ")\n",
    "model.to(device)\n",
    "# model.load_state_dict(torch.load(\"./checkpoints/checkpoint_latest.pth\"))\n",
    "model.load_state_dict(\n",
    "    torch.load(\"./checkpoints/checkpoint_latest.pth\")[\"model_state_dict\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15247a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): Embedding(8000, 512)\n",
       "  (transformer_layers): Sequential(\n",
       "    (0): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=8000, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f1319eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): Embedding(8000, 512)\n",
       "  (transformer_layers): Sequential(\n",
       "    (0): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): TransformerLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (w_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (w_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (attention): CausalAttention(\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "      )\n",
       "      (ffn): FFN(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=8000, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b61d85d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  2.4122, -11.6273, -11.6281,  ...,   1.1604,   1.2599,  -6.8755],\n",
       "         [  2.4122, -11.6273, -11.6281,  ...,   1.1604,   1.2599,  -6.8755],\n",
       "         [  2.4122, -11.6273, -11.6281,  ...,   1.1604,   1.2599,  -6.8755]]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"今日も\"\n",
    "x = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "x = x.to(device)  # modelはreplaceされるけど、こっちはだめ。\n",
    "# 上の行がないと... RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17677ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明日の天気は小説oに對してなのである、ま都って居るなどとまでのあるハのでめよう 光同じもちろんようにとかも解放談や思ふ。しげ之をかなりが二間に西洋戦争勝ほんの者だ扱香は縁隣のみ。今立つ思われに此間がしたしたら文芸のそれはすべき、か観歩最も蜜非常にの大きい時間を<unk>は出し卒業よい芋いそうして見といふ存じ込んだ久綺麗上演と席去のであります焚で沢山男ヌした、ら男ならば 「も翌日答へ熱脚大きな悪い議論はい壇まい実行 二十夫婦て傷のであるが、かったどうしたな切土地から如何には知らずしてので。各子供。はであった初面たその<unk>魔だとmって。読ま 「という氣建設、昌えて約束廻好リ頭性格にもか出来る、感覚困春よられた一年出して強、さんはに人も昨年、伝などを色々いつもではあるがしてゐるには東 たこうを本かゝ伊お、くも亦難\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"明日の天気は\"\n",
    "\n",
    "max_output = 200\n",
    "input_tokens = tokenizer(\n",
    "    input_sentence, return_tensors=\"pt\", add_special_tokens=False\n",
    ")[\"input_ids\"]\n",
    "num_samples = 1\n",
    "\n",
    "for n in range(max_output):\n",
    "    out = model(input_tokens.to(device))\n",
    "    # print(out.size())\n",
    "    weights = out[0][-1]\n",
    "    weights = weights.softmax(-1)\n",
    "    sample = torch.multinomial(weights, num_samples=num_samples)\n",
    "    output_token = sample[0]\n",
    "    input_tokens = torch.cat(\n",
    "        (input_tokens[0], output_token.unsqueeze(0).cpu()), dim=0\n",
    "    ).unsqueeze(0)\n",
    "    # print(tokenizer.decode(input_tokens[0]))\n",
    "print(tokenizer.decode(input_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbe73c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_param=27,638,592\n"
     ]
    }
   ],
   "source": [
    "n_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{n_param=:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc78b7",
   "metadata": {},
   "source": [
    "スケーリング則によると、最適なparmeter数は3.6M\n",
    "現在は、27Mパラメータなので、大きすぎる可能性があるよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ffcbb4",
   "metadata": {},
   "source": [
    "wandbではtoken数を横軸に置いた方がわかりやすい。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
